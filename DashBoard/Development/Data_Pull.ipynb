{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Gathering\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as dt\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_qualifier='https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "file_qualifier_confirmed='Consolidated_Data/Time_Series_Confirmed'\n",
    "file_qualifier_deaths='Consolidated_Data/Time_Series_Deaths'\n",
    "file_qualifier_recovered='Consolidated_Data/Time_Series_Recovered'\n",
    "confirmed_file='time_series_covid19_confirmed_global'\n",
    "deaths='time_series_covid19_deaths_global'\n",
    "recovered='time_series_covid19_recovered_global'\n",
    "extension='.csv'\n",
    "file_list=[confirmed_file,deaths,recovered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_data(date_val):\n",
    "    start=dt.datetime.now()\n",
    "    url = url_qualifier + date_val + extension\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if str(response)=='<Response [200]>':\n",
    "          soup= BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "          print('get_url failed. Bad response received : {}'.format(str(response)))\n",
    "    print('Total Execution Time {}'.format(dt.datetime.now()-start))\n",
    "    return soup    \n",
    "\n",
    "def extract_headers(soup_data):\n",
    "    html_text=soup_data.findAll('tr')\n",
    "    listed_html_text=list(html_text)\n",
    "    print('Length of listed html text: {}'.format(len(listed_html_text)))\n",
    "    cols=[]\n",
    "    b=list(listed_html_text[0])\n",
    "    for i in range(0,len(b)):\n",
    "        if str(b[i])!= '\\n':\n",
    "            node=re.match(\"<td class=*\",str(b[i]))\n",
    "            if not node:\n",
    "                value=re.match('<th>(.*)</th>',str(b[i])).group(1)\n",
    "                cols.append(value)\n",
    "    return cols\n",
    "\n",
    "def extract_data(soup_data):\n",
    "    data_array=[]\n",
    "    html_text=soup_data.findAll('tr')\n",
    "    listed_html_text=list(html_text)\n",
    "    for j in range(1,len(listed_html_text)):\n",
    "        b=list(listed_html_text[j])\n",
    "        d=[]\n",
    "        for i in range(0,len(b)):\n",
    "            if str(b[i])!= '\\n':\n",
    "                node=re.match(\"<td class=*\",str(b[i]))\n",
    "                if not node:\n",
    "                    value=re.match('<td>(.*)</td>',str(b[i])).group(1)\n",
    "                    d.append(value)\n",
    "        data_array.append(d)\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/santosh/Documents/Python/Corona_Virus/Development'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction started for time_series_covid19_confirmed_global\n",
      "Total Execution Time 0:00:04.422118\n",
      "Length of listed html text: 257\n",
      "Data extraction complete for Date time_series_covid19_confirmed_global. Shape of data (256, 74).\n",
      "Data extraction started for time_series_covid19_deaths_global\n",
      "Total Execution Time 0:00:05.530475\n",
      "Length of listed html text: 257\n",
      "Data extraction complete for Date time_series_covid19_deaths_global. Shape of data (256, 74).\n",
      "Data extraction started for time_series_covid19_recovered_global\n",
      "Total Execution Time 0:00:04.200322\n",
      "Length of listed html text: 243\n",
      "Data extraction complete for Date time_series_covid19_recovered_global. Shape of data (242, 74).\n"
     ]
    }
   ],
   "source": [
    "for k in file_list:  \n",
    "    print('Data extraction started for {}'.format(k))   \n",
    "    soup=get_url_data(k)\n",
    "    cols=extract_headers(soup)\n",
    "    data_array=extract_data(soup)\n",
    "    data = pd.DataFrame(data_array, columns=cols)\n",
    "    filename='Timeline_'+k+extension\n",
    "    data.to_csv(filename,encoding='utf-8',index=False)\n",
    "    print('Data extraction complete for Date {}. Shape of data {}.'.format(k,data.shape))\n",
    "    time.sleep(60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
